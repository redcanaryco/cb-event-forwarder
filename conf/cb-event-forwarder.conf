[bridge]

###########
#General Config Options
##########

#
# How many process pools should the script spin up to
# process events off of the bus.
message_processor_count=4

#
# This is a name that gets populated in all JSON objects
# as "cb_server".  This can help distinguish messages when
# data from multiple Carbon Black deployments are merged
# into a single source
server_name=demo

# enable extra debugging output
debug=0

# port for HTTP diagnostics
http_server_port=33706

#
# Bus Connection Options
#
# There are two deployment options:
#
# 1) For small deployments, or for low volume subscriptions (such as new binaries, feed/watchlist hits),
#    you can install this connector directly on the Carbon Black server. In this case, leave the following
#    three configuration options blank and the service will connect to the local RabbitMQ instance using
#    the credentials from the /etc/cb/cb.conf file.
#
# 2) For larger deployments, or for high volume subscriptions (such as raw endpoint events), it is recommended
#    to install this connector on its own dedicated machine. In this case, fill the following three configuration
#    options with the RabbitMQUser, RabbitMQPassword, and the IP/hostname of the Carbon Black server or master
#    node respectively. You will have to ensure that your host can connect to TCP port 5004 on the Carbon Black
#    server.
#
rabbit_mq_username=cb
# rc
#rabbit_mq_password=Euj5a1QWjCsUrliA
#cb_server_hostname=rc-cb.redcanary.core
# demo
#rabbit_mq_password=yyhf4PQ6nqV5ISZN

rabbit_mq_password=zFqFfA5npOYrNvUu
cb_server_hostname=as-cb.redcanary.core

#rabbit_mq_password=WO139ZQx6DcMHwsn
#cb_server_hostname=cb.bit9.my.redcanary.co

#rabbit_mq_password=sjnE0QaevxhE4p01
#cb_server_hostname=cbcloudtest.redcanary.core

#cb_server_hostname=dukemaster-cb.redcanary.core
#rabbit_mq_password=WZHt1wgeIb9Fcm8z

rabbit_mq_port=5004

rabbit_mq_use_tls=false
rabbit_mq_key=/Users/crothe/mykey/key.key
rabbit_mq_cert=/Users/crothe/mykey/cert.crt
rabbit_mq_ca_cert=/Users/crothe/mykey/ca.crt
rabbit_mq_queue_name=redcanary-dev

#
# The cb-event-forwarder can optionally place deep links into the JSON or LEEF output so users can have
# one-click access to process, binary, or sensor context. For example, a watchlist process hit will now include:
#  .docs[0].link_sensor: https://cbtests/#/host/7
#  .docs[0].link_process: https://cbtests/#analyze/00000007-0000-0fd4-01d1-209aa22a57ee/1
#  .docs[0].link_parent: https://cbtests/#analyze/00000007-0000-0fc8-01d1-209aa208f788/1
#  .docs[0].link_process_md5: https://cbtests/#/binary/445C3E95C8CB05403AEDAEC3BAAA3A1D
#
# Raw endpoint events will include a "link_process", and binary watchlist hits will include a "link_md5"
#
# To enable these links, uncomment and place the base URL of your Carbon Black server into the cb_server_url variable
# below.
#
# cb_server_url=https://my.company.cb.server

#########
# Output Options
#########

#
# Configure the specific output.
# Valid options are: 'udp', 'tcp', 'file', 'stdout', 's3'
#
#  udp - Have the events sent over a UDP socket
#  tcp - Have the events sent over a TCP socket
#  file - Output the events to a rotating file
#  s3 - Place in S3 bucket (not officially supported)
#  syslog - Send the events to a syslog server
#
output_type=s3

# Configure the output format
# valid options are: 'leef', 'json'
#
# default is 'json'
# Use 'leef' for pushing events to IBM QRadar, 'json' otherwise
#
output_format=json

#
# Output specific configuration
# These only have meaning if the option
# is enabled
#

# default to /var/cb/data/event_bridge_output.json
# outfile=/var/cb/data/event_bridge_output.json
outfile=/tmp/event_bridge_output.json

# tcpout=IP:port - ie 1.2.3.5:8080
tcpout=

# udpout=IP:port - ie 1.2.3.5:8080
udpout=

# options for S3 support
# s3out: can be an S3 bucket name (defaults to us-east-1 region)
#        or (temp-file-directory):(region):(bucket-name)
#        by default, the temp-file-directory is /var/cb/data/event-forwarder.
#
# for more s3 options, see the [s3] section below.
s3out=/tmp/forwarder:us-east-1:rc-temporary

# options for syslog output
# syslogout:
#   uses the format <protocol>:<hostname>:<port>
#   where <protocol> can be:
#      tcp+tls:      TCP over TLS/SSL
#      tcp:          plaintext TCP
#      udp:          plaintext UDP

# example:
#   tcp+tls:syslog.company.com:514
syslogout=

#########
# Configuration for which events are captured
#
# To specify multiple events use comma as a separator
# e.g. events_raw_sensor=ingress.event.process,ingress.event.procstart
#
#
# For more info on supported event types see
# https://github.com/carbonblack/cbapi/tree/master/server_apis
#
# Note: To enable raw sensor events you must also edit the Carbon Black config
#  file (cb.conf) and enable the appropriate events by changing the config
#  option DatastoreBroadcastEventTypes.
#
# If you intend to enable raw sensor events on a Cb Enterprise Response 5.2+ server,
#  consider using the "raw sensor exchange" for enhanced performance and reduced
#  load on the Cb server. The raw exchange forwards the compressed data received
#  from the endpoint sensor unchanged to the event-forwarder. The raw sensor
#  exchange should be used if you are forwarding moduleload, filemod, or regmod
#  endpoint events as these represent the vast majority of the event types.
#
# To use the "raw sensor exchange", first uncomment the "use_raw_sensor_exchange"
#  option below:
use_raw_sensor_exchange=false
#
#  then enable the "raw sensor exchange" in cb.conf:
#  EnableRawSensorDataBroadcast=true
#
# Note: To enable binaryinfo. events you need to enable EnableSolrBinaryInfoNotifications=True
#  within the cb.conf
#########

# Raw Sensor (endpoint) Events
# Includes:
#   ingress.event.process
#   ingress.event.procstart
#   ingress.event.netconn
#   ingress.event.procend
#   ingress.event.childproc
#   ingress.event.moduleload
#   ingress.event.module
#   ingress.event.filemod
#   ingress.event.regmod
#   ingress.event.tamper
#   ingress.event.crossprocopen
#   ingress.event.remotethread
#   ingress.event.processblock
#   ingress.event.emetmitigation
#   ALL for all of the above
#   0 - to disable all raw sensor events.
events_raw_sensor=ingress.event.procstart,ingress.event.procend,ingress.event.netconn,ingress.event.filemod,ingress.event.regmod,ingress.event.childproc,ingress.event.crossprocopen,ingress.event.remotethread
#events_raw_sensor=ingress.event.procstart,ingress.event.netconn

# Watchlist Hits
# Includes:
#  watchlist.hit.process
#  watchlist.hit.binary
#  watchlist.storage.hit.process
#  watchlist.storage.hit.binary
events_watchlist=0

# Feed Hits
# Includes:
#   feed.ingress.hit.process
#   feed.ingress.hit.binary
#   feed.ingress.hit.host
#   feed.storage.hit.process
#   feed.storage.hit.binary
#   feed.query.hit.process
#   feed.query.hit.binary
#   ALL for all of the above
#   0 - to disable all raw sensor events
events_feed=0

# Alert Events
# Includes:
#   alert.watchlist.hit.ingress.process
#   alert.watchlist.hit.ingress.binary
#   alert.watchlist.hit.ingress.host
#   alert.watchlist.hit.query.process
#   alert.watchlist.hit.query.binary
#   ALL for all of the above
#   0 - to disable all raw sensor events
events_alert=0

# Binary Observed Events
# Includes:
#   binaryinfo.observed
#   binaryinfo.host.observed
#   binaryinfo.group.observed
events_binary_observed=0

# Binary Upload Events
# Includes:
#   binarystore.file.added
events_binary_upload=0

#########
# S3 configuration section
#
# The following are advanced configuration options for uploading output to Amazon S3 buckets.
#########

[s3]
# Uncomment server_side_encryption below to enable SSE on uploaded files to your S3 bucket
server_side_encryption=AES256

# Set the following ACL policy on all files uploaded to your S3 bucket
# acl_policy=bucket-owner-full-control

# Use the following credential profile to connect to S3.
# See http://docs.aws.amazon.com/cli/latest/userguide/cli-chap-getting-started.html for more information on
# AWS credential storage and credential profiles. By default, the S3 output will use the default
# credential storage location of $HOME/.aws/credentials with the "default" credential profile.
#
# The credential_profile can be specified as the profile name, using the default storage location, or
# you can also specify the filename where the credentials are stored by using a colon separated format:
# for example, to look for the AWS credentials in the file /etc/cb/aws.creds, and use profile "production":
# set credential_profile to /etc/cb/aws.creds:production.

# credential_profile=default

# Use the following to create event forwarder logs under a specified object prefix
# If specified logs will be stored under <bucketname>/<object_prefix>/event-forwarder.<timestamp>
# This is useful if multiple forwarders are to use the same s3 bucket
object_prefix=prefixtest
verbose_key=true
bundleSendTimeout=20

[syslog]
# Uncomment ca_cert to specify a file containing PEM-encoded CA certificates for verifying the peer
# server when using TLS+TCP syslog
# ca_cert=/etc/cb/integrations/event-forwarder/ca-certs.pem

# Uncomment tls_verify and set to "false" in order to disable verification of the peer server certificate
# when using TLS+TCP syslog
# tls_verify=false

# Uncomment client_key and client_cert and set to files containing PEM-encoded private key and public
# certificate when using client TLS certificates when using TLS+TCP syslog
# client_key=/etc/cb/integrations/event-forwarder/client-key.pem
# client_cert=/etc/cb/integrations/event-forwarder/client-cert.pem

[kafka]
brokers=localhost:9092
topic_suffix=-1

[audit]
enabled=false
redis_host=localhost
redis_database_number=0
pipeline_size=2000
